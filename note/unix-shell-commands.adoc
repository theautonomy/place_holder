= Essential Unix Shell Commands for Developers
:revealjsdir: https://cdn.jsdelivr.net/npm/reveal.js@4.3.1
:revealjs_theme: none
:revealjs_customtheme: styles/custom-theme.css
:customcss: styles/custom-theme-custom.css
:revealjs_transition: slide
:revealjs_transitionSpeed: default  
:revealjs_controls: true
:revealjs_progress: true
:revealjs_keyboard: true
:revealjs_navigationMode: default
:revealjs_width: 1600
:revealjs_height: 1200
:revealjs_margin: 0
:revealjs_slideNumber: c/t

== Essential Unix Shell Commands for Developers

=== File Operations
[source,bash]
----
# Find files by name or pattern
find . -name "*.js" -type f
find . -name "*test*" -type f

# Count files in directory
ls -1 | wc -l
find . -type f | wc -l

# Search and replace in files
sed -i 's/old_text/new_text/g' file.txt
grep -r "pattern" . --include="*.js"
----

=== Text Processing & Search
[source,bash]
----
# Search content in files
grep -n "function" *.js
ag "TODO" --ignore="node_modules"

# Replace text across multiple files
find . -name "*.js" -exec sed -i 's/old/new/g' {} +

# Count lines of code
wc -l *.js
find . -name "*.js" | xargs wc -l
----

=== xargs Command Examples
[source,bash]
----
# Delete files found by find
find . -name "*.tmp" | xargs rm

# Process files with spaces in names
find . -name "*.log" -print0 | xargs -0 gzip

# Run command on each line
echo -e "file1\nfile2\nfile3" | xargs -I {} cp {} backup/

# Parallel processing
find . -name "*.jpg" | xargs -P 4 -I {} convert {} {}.png

# Limit arguments per command
ls *.txt | xargs -n 3 echo "Processing:"

# Conditional execution
find . -name "node_modules" | xargs -r rm -rf
----

=== sed Command Examples
[source,bash]
----
# Basic substitution
sed 's/old/new/' file.txt
sed 's/old/new/g' file.txt          # Global replace
sed -i 's/old/new/g' file.txt       # In-place edit

# Line operations
sed '5d' file.txt                   # Delete line 5
sed '2,5d' file.txt                 # Delete lines 2-5
sed -n '10,20p' file.txt            # Print lines 10-20

# Pattern-based operations
sed '/pattern/d' file.txt           # Delete lines matching pattern
sed '/^$/d' file.txt                # Delete empty lines
sed '/^#/d' file.txt                # Delete comment lines

# Advanced replacements
sed 's/\([0-9]\+\)/[\1]/g' file.txt # Wrap numbers in brackets
sed 's/.*ERROR.*/FOUND ERROR/' file.txt
----

=== find Command Examples
[source,bash]
----
# Find by name and type
find . -name "*.js" -type f
find . -name "test*" -type d
find . -iname "*.LOG" -type f        # Case insensitive

# Find by size and time
find . -size +100M                  # Files larger than 100MB
find . -mtime -7                    # Modified in last 7 days
find . -atime +30                   # Not accessed in 30+ days

# Find and execute commands
find . -name "*.tmp" -delete
find . -name "*.js" -exec grep -l "TODO" {} \;
find . -name "*.log" -exec gzip {} \;

# Complex conditions
find . -name "*.js" -not -path "*/node_modules/*"
find . \( -name "*.js" -o -name "*.ts" \) -type f
find . -name "*.py" -size +1k -mtime -30
----

=== Directory Navigation & Management
[source,bash]
----
# Quick directory navigation
cd -  # Go to previous directory
pushd /path && popd  # Directory stack

# Disk usage
du -sh *  # Size of directories
df -h     # Disk space usage

# Create directory structure
mkdir -p path/to/nested/dirs
----

=== Process & System Monitoring
[source,bash]
----
# Find running processes
ps aux | grep "node"
pgrep -f "python"

# Monitor file changes
watch "ls -la"
tail -f logfile.txt

# Network connections
netstat -tulpn | grep :8080
lsof -i :3000
----

=== awk Command Examples
[source,bash]
----
# Basic field processing
awk '{print $1, $3}' file.txt       # Print columns 1 and 3
awk -F: '{print $1}' /etc/passwd     # Use : as field separator
awk 'NR==5' file.txt                 # Print line 5

# Conditional processing
awk '$3 > 100 {print $1, $3}' file.txt
awk '/ERROR/ {print NR, $0}' log.txt

# Calculations and summaries
awk '{sum += $1} END {print sum}' numbers.txt
awk '{count++} END {print count " lines"}' file.txt
----

=== curl Command Examples
[source,bash]
----
# Basic HTTP requests
curl -X GET https://api.example.com/users
curl -X POST -d '{"name":"John"}' -H "Content-Type: application/json" api.com/users
curl -X PUT -d @data.json -H "Content-Type: application/json" api.com/users/1
curl -X DELETE https://api.example.com/users/1

# File operations and downloads
curl -O https://example.com/file.zip  # Download with original name
curl -o myfile.zip https://example.com/file.zip
curl -L https://example.com/redirect  # Follow redirects
curl -C - -O https://example.com/large-file.zip  # Resume download

# Headers and authentication
curl -H "Authorization: Bearer token123" api.com/data
curl -H "Accept: application/json" -H "User-Agent: MyApp/1.0" api.com
curl -u username:password https://api.example.com
curl -i https://example.com           # Include response headers
curl -I https://example.com           # Headers only (HEAD request)

# Form data and file uploads
curl -F "file=@document.pdf" https://api.example.com/upload
curl -d "name=John&email=john@example.com" https://api.example.com/form
curl --data-urlencode "message=Hello World!" https://api.example.com/post

# Advanced options
curl -v https://api.example.com       # Verbose output
curl -s https://api.example.com | jq  # Silent mode with jq
curl -w "%{http_code}\n" https://example.com  # Show response code
curl --connect-timeout 10 --max-time 30 https://slow-api.com
----

=== sort & uniq Examples
[source,bash]
----
# Sorting operations
sort file.txt                        # Alphabetical sort
sort -n numbers.txt                  # Numerical sort
sort -k2 file.txt                    # Sort by column 2
sort -r file.txt                     # Reverse sort

# Unique operations
sort file.txt | uniq                 # Remove duplicates
sort file.txt | uniq -c              # Count occurrences
sort file.txt | uniq -d              # Show only duplicates
----

=== jq Command Examples
[source,bash]
----
# Basic JSON processing
echo '{"name":"John","age":30}' | jq '.'
echo '{"name":"John","age":30}' | jq '.name'
echo '{"name":"John","age":30}' | jq -r '.name'  # Raw output

# Array operations
echo '[1,2,3,4,5]' | jq '.[2]'       # Get 3rd element
echo '[1,2,3,4,5]' | jq '.[]'        # Expand array
echo '[1,2,3,4,5]' | jq 'length'     # Array length

# Filtering and mapping
jq '.users[] | select(.age > 25)' data.json
jq '.users[] | {name: .name, email: .email}' data.json
jq '.users | map(.name)' data.json

# Complex queries
jq '.items[] | select(.status == "active") | .name' api.json
jq 'group_by(.category) | map({category: .[0].category, count: length})' data.json
curl api.com/users | jq '.data[] | select(.role == "admin")'
----

=== HTTPie Command Examples
[source,bash]
----
# Basic HTTP requests
http GET https://api.example.com/users
http POST https://api.example.com/users name=John age:=30
http PUT https://api.example.com/users/1 name=Jane
http DELETE https://api.example.com/users/1

# Headers and authentication
http GET api.example.com/data Authorization:"Bearer token123"
http GET api.example.com/secure --auth username:password
http GET api.example.com/api Accept:application/json

# JSON and form data
http POST api.example.com/users name=John email=john@example.com
http --form POST api.example.com/upload file@./document.pdf
http POST api.example.com/data < data.json

# Advanced options
http --verbose GET api.example.com/debug    # Show request/response
http --download GET api.example.com/file.zip
http --session=user GET api.example.com/profile  # Session persistence
----

=== grep Command Examples
[source,bash]
----
# Basic pattern matching
grep "error" logfile.txt
grep -i "ERROR" logfile.txt             # Case insensitive
grep -v "debug" logfile.txt             # Invert match (exclude)
grep -n "function" script.js            # Show line numbers

# Recursive and file operations
grep -r "TODO" src/                     # Recursive search
grep -r "import" --include="*.js" .     # Specific file types
grep -l "class" *.py                    # Files with matches only
grep -c "error" logfile.txt             # Count matches

# Regular expressions
grep "^Error" logfile.txt               # Lines starting with "Error"
grep "Error$" logfile.txt               # Lines ending with "Error"
grep "[0-9]\{3\}" file.txt              # Three consecutive digits
grep -E "(error|warning)" logfile.txt   # Extended regex (OR)

# Context and formatting
grep -A 3 "error" logfile.txt           # 3 lines after match
grep -B 2 "error" logfile.txt           # 2 lines before match
grep -C 2 "error" logfile.txt           # 2 lines before and after
grep --color=always "pattern" file.txt  # Highlight matches
----

=== Command Pipeline Examples
[source,bash]
----
# Log analysis pipelines
cat access.log | grep "GET" | grep -v "200" | wc -l
tail -f error.log | grep -i "error" | awk '{print $1, $4}'
ps aux | grep "node" | grep -v "grep" | awk '{print $2}' | xargs kill

# File processing chains
find . -name "*.js" | xargs grep -l "TODO" | head -10
ls -la | grep "^d" | awk '{print $9}' | sort
cat data.csv | cut -d',' -f2 | sort | uniq -c | sort -nr

# API and data processing
curl -s api.example.com/users | jq '.data[]' | jq '.name' | sort
grep -r "import" src/ | cut -d: -f1 | sort | uniq -c | sort -nr
find . -name "*.log" | xargs grep "ERROR" | cut -d: -f2 | sort | uniq

# System monitoring chains
netstat -tuln | grep ":80 " | wc -l
ps aux | sort -nrk 3,3 | head -5 | awk '{print $3, $11}'
df -h | grep -v "tmpfs" | awk '$5 > 80 {print $1, $5}'

# Git and version control
git log --oneline | head -10 | awk '{print $1}' | xargs -I {} git show --name-only {}
git diff --name-only HEAD~1 | grep "\.js$" | xargs grep -l "function"
----

== Git Operations & Tips

=== Basic Git Operations
[source,bash]
----
# Find files changed in last commit
git diff --name-only HEAD~1

# Search git history
git log --grep="bug fix"
git log -p -S "function_name"

# Show files with conflicts
git diff --name-only --diff-filter=U
----

=== Branch Management
[source,bash]
----
# Quick branch switching
git checkout -b feature/new-feature
git switch -c feature/another-way

# Delete merged branches
git branch --merged | grep -v main | xargs git branch -d

# Rename current branch
git branch -m new-branch-name

# Track remote branch
git branch -u origin/main
----

=== Commit Management
[source,bash]
----
# Amend last commit
git commit --amend --no-edit
git commit --amend -m "New message"

# Interactive rebase (last 3 commits)
git rebase -i HEAD~3

# Cherry-pick specific commit
git cherry-pick abc123

# Undo last commit (keep changes)
git reset --soft HEAD~1
----

=== Working with Changes
[source,bash]
----
# Stash with message
git stash push -m "work in progress"
git stash list
git stash pop

# Partial staging
git add -p file.txt

# Show what will be committed
git diff --cached

# Unstage file
git restore --staged file.txt
----

== Essential Vim Tips for Developers

=== Basic Navigation & Movement
[source,vim]
----
# Line navigation
0    # Beginning of line
$    # End of line
gg   # Beginning of file
G    # End of file
:42  # Go to line 42

# Word movement
w    # Next word
b    # Previous word
e    # End of current word
----

=== Editing & Text Manipulation
[source,vim]
----
# Insert modes
i    # Insert before cursor
a    # Insert after cursor
o    # New line below
O    # New line above

# Delete operations
dd   # Delete line
dw   # Delete word
x    # Delete character
D    # Delete to end of line

# Copy & paste
yy   # Copy line
yw   # Copy word
p    # Paste after cursor
P    # Paste before cursor
----

=== Search & Replace
[source,vim]
----
# Search
/pattern     # Search forward
?pattern     # Search backward
n            # Next match
N            # Previous match

# Replace
:%s/old/new/g        # Replace all in file
:s/old/new/g         # Replace in current line
:%s/old/new/gc       # Replace with confirmation
----

=== File Operations & Buffers
[source,vim]
----
# File operations
:w           # Save file
:wq          # Save and quit
:q!          # Quit without saving
:e filename  # Open file

# Multiple files
:split       # Horizontal split
:vsplit      # Vertical split
Ctrl+w w     # Switch between windows
:bn          # Next buffer
:bp          # Previous buffer
----

== Essential Splunk Search Tips

=== Basic Search Syntax
[source,splunk]
----
# Basic searches
index=web error
host=server1 source="/var/log/app.log"
sourcetype=access_combined status=500

# Time ranges
earliest=-1h latest=now
earliest=-7d@d latest=@d

# Field searches
user=admin action=login
method=POST uri="/api/*"
----

=== Search Commands & Operators
[source,splunk]
----
# Statistical commands
| stats count by host
| stats avg(response_time) by service
| stats dc(user) as unique_users

# Filtering and sorting
| where response_time > 1000
| sort -_time
| head 100 | tail 10

# Field manipulation
| eval new_field=field1+field2
| rex field=_raw "(?<user>\w+)"
| lookup users.csv username OUTPUT department
----

=== Data Analysis & Visualization
[source,splunk]
----
# Time charts
| timechart span=1h count by status
| timechart avg(response_time)

# Top values
| top 10 user
| rare limit=5 error_code

# Transformations
| dedup host, service
| transaction sessionid
| bucket _time span=5m
----

=== Advanced Search Techniques
[source,splunk]
----
# Subsearches
[search error | return host]

# Joins
| join user [search index=users]

# Lookups and field extractions
| inputlookup threats.csv
| outputlookup myresults.csv
| extract pairdelim="&" kvdelim="="

# Regular expressions
| regex _raw="ERROR.*database"
| rex "(?i)user=(?<username>[^\s]+)"
----